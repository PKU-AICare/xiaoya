{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Xiaoya-Core","text":"<p>xiaoya 2.0 core</p>"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>xiaoya/ # root\n    pyehr/ # yhzhu99/pyehr project\n    data/ # import user uploaded data, merge data tables, stats...\n    pipeline/ # model training and evaluation, ...\n    analysis/ # analysis modules\n    plot/ # plot modules\n</code></pre>"},{"location":"#sample-usages","title":"Sample Usages","text":""},{"location":"#pipeline-of-training-and-predicting","title":"Pipeline of Training and Predicting","text":"<pre><code>import pandas as pd\n\nfrom xiaoya.data import DataHandler\nfrom xiaoya.pipeline import Pipeline\n\nlabtest_data = pd.read_csv('datasets/raw_labtest_data.csv')\nevents_data = pd.read_csv('datasets/raw_events_data.csv')\ntarget_data = pd.read_csv('datasets/raw_target_data.csv')\ndata_handler = DataHandler(labtest_data=labtest_data, events_data=events_data, target_data=target_data)\ndata_handler.execute()\n\npl = Pipeline()\nresult = pl.execute()\nprint(result)\n</code></pre>"},{"location":"#analysis-and-plot","title":"Analysis and Plot","text":"<ul> <li>Dataset Visualization</li> </ul> <pre><code>import pandas as pd\n\nfrom xiaoya.data import DataHandler\nfrom xiaoya.plot import plot_vis_dataset\n\nlabtest_data = pd.read_csv('datasets/raw_labtest_data.csv')\nevents_data = pd.read_csv('datasets/raw_events_data.csv')\ntarget_data = pd.read_csv('datasets/raw_target_data.csv')\ndata_handler = DataHandler(labtest_data=labtest_data, events_data=events_data, target_data=target_data)\ndata_handler.execute()\nresult = data_handler.analyze_dataset()\nplot_vis_dataset(result['detail'], save_path='./output/vis_data')\n</code></pre> <ul> <li>Plot Feature Importance histogram</li> </ul> <pre><code>import pandas as pd\n\nfrom xiaoya.pipeline import Pipeline\nfrom xiaoya.analysis import DataAnalyzer\nfrom xiaoya.plot import plot_feature_importance\n\npl = Pipeline(model='ConCare')\npl.execute()\n\ndata_analyzer = DataAnalyzer(pl.config, pl.model_path)\ntrain_raw = pd.read_csv('datasets/train_raw.csv')\ntrain_x = pd.read_pickle('datasets/train_x.pkl')\nresult = data_analyzer.feature_importance(\n    df=train_raw,\n    x=train_x,\n    patient_index=0\n)\nplot_feature_importance(result['detail'], save_path='./output/')\n</code></pre> <ul> <li>Plot Patient Risk curve</li> </ul> <pre><code>import pandas as pd\n\nfrom xiaoya.pipeline import Pipeline\nfrom xiaoya.analysis import DataAnalyzer\nfrom xiaoya.plot import plot_risk_curve\n\npl = Pipeline(model='AdaCare')\npl.execute()\n\ndata_analyzer = DataAnalyzer(pl.config, pl.model_path)\ntrain_raw = pd.read_csv('datasets/train_raw.csv')\ntrain_x = pd.read_pickle('datasets/train_x.pkl')\ntrain_mask = pd.read_pickle('datasets/train_missing_mask.pkl')\nresult = data_analyzer.risk_curve(\n    df=train_raw,\n    x=train_x,\n    mask=train_mask,\n    patient_index=0\n)\nplot_risk_curve(result, save_path='./output/')\n</code></pre> <ul> <li>Plot Patient Embedding and Trajectory</li> </ul> <pre><code>import pandas as pd\n\nfrom xiaoya.pipeline import Pipeline\nfrom xiaoya.analysis import DataAnalyzer\nfrom xiaoya.plot import plot_patient_embedding\n\npl = Pipeline(model='ConCare')\npl.execute()\n\ndata_analyzer = DataAnalyzer(pl.config, pl.model_path)\ntrain_x = pd.read_pickle('datasets/train_x.pkl')\ntrain_pid = pd.read_pickle('datasets/train_pid.pkl')\ntrain_record_time = pd.read_pickle('datasets/train_record_time.pkl')\ntrain_mean_age = pd.read_pickle('datasets/train_mean.pkl')['Age']\ntrain_std_age = pd.read_pickle('datasets/train_std.pkl')['Age']\nresult = data_analyzer.data_dimension_reduction(\n    x = train_x,\n    pid = train_pid,\n    record_time = train_record_time,\n    mean_age = train_mean_age,\n    std_age = train_std_age\n)\nplot_patient_embedding(result['detail'], save_path='./output/')\n</code></pre> <ul> <li>AI Advice</li> </ul> <pre><code>import pandas as pd\n\nfrom xiaoya.pipeline import Pipeline\nfrom xiaoya.analysis import DataAnalyzer\n\npl = Pipeline(model='ConCare')\npl.execute()\n\ndata_analyzer = DataAnalyzer(pl.config, pl.model_path)\ntrain_raw = pd.read_csv('datasets/train_raw.csv')\ntrain_x = pd.read_pickle('datasets/train_x.pkl')\ntrain_mask = pd.read_pickle('datasets/train_missing_mask.pkl')\n\nresult = data_analyzer.ai_advice(\n    df=train_raw,\n    x=train_x,\n    mask=train_mask,\n    patient_index=0,\n    time_index=-1\n)\nprint(result)\n</code></pre>"},{"location":"analysis/data_analyzer/","title":"Data Analyzer","text":"<p>DataAnalyzer</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Dict</code> <p>Dict. the config of the pipeline.</p> required <code>model_path</code> <code>str</code> <p>str. the path of the model.</p> required"},{"location":"analysis/data_analyzer/#xiaoya.analysis.data_analyzer.DataAnalyzer.adaptive_feature_importance","title":"<code>adaptive_feature_importance(df, x, patient_index=None, patient_id=None)</code>","text":"<p>Return the importance scores of a patient.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>List</code> <p>torch.Tensor. the input of the patient.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>Dict. the importance scores.</p>"},{"location":"analysis/data_analyzer/#xiaoya.analysis.data_analyzer.DataAnalyzer.ai_advice","title":"<code>ai_advice(df, x, mask, time_index, patient_index=None, patient_id=None)</code>","text":"<p>Return the advice of the AI system.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>pd.DataFrame. the dataframe of the patient.</p> required <code>x</code> <code>List</code> <p>List. the input of the patient.</p> required <code>mask</code> <code>List</code> <p>Optional[List]. the missing mask of the patient.</p> required <code>patient_index</code> <code>Optional[int]</code> <p>Optional[int]. the index of the patient in dataframe.</p> <code>None</code> <code>patient_id</code> <code>Optional[int]</code> <p>Optional[int]. the patient ID.</p> <code>None</code> <code>time_index</code> <code>int</code> <p>int. the time index of the patient.</p> required <p>Returns:</p> Type Description <code>List</code> <p>List. the advice of the AI system.</p>"},{"location":"analysis/data_analyzer/#xiaoya.analysis.data_analyzer.DataAnalyzer.data_dimension_reduction","title":"<code>data_dimension_reduction(x, pid, record_time, mean_age, std_age, method='PCA', dimension=2, target='outcome')</code>","text":"<p>Return data to draw dimension reduction.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>List</code> <p>List. the input of the patient.</p> required <code>pid</code> <code>List</code> <p>List. the patient ID.</p> required <code>record_time</code> <code>List</code> <p>List. the record time of the patient.</p> required <code>mean_age</code> <code>Optional[float]</code> <p>Optional[float]. the mean age of the patient.</p> required <code>std_age</code> <code>Optional[float]</code> <p>Optional[float]. the std age of the patient.</p> required <code>method</code> <code>str</code> <p>str. the method of dimension reduction, one of \"PCA\" and \"TSNE\".</p> <code>'PCA'</code> <code>dimension</code> <code>int</code> <p>int. the dimension of dimension reduction, one of 2 and 3.</p> <code>2</code> <code>target</code> <code>str</code> <p>str. the target of the model, one of \"outcome\", \"los\" and \"multitask\".</p> <code>'outcome'</code> <p>Returns:</p> Type Description <code>List</code> <p>List. the data to draw dimension reduction.</p>"},{"location":"analysis/data_analyzer/#xiaoya.analysis.data_analyzer.DataAnalyzer.feature_importance","title":"<code>feature_importance(df, x, patient_index=None, patient_id=None)</code>","text":"<p>Return feature importance of a patient.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>pd.DataFrame. the dataframe of the patient.</p> required <code>x</code> <code>List</code> <p>List. the input of the patient.</p> required <code>patient_index</code> <code>Optional[int]</code> <p>Optional[int]. the index of the patient in dataframe.</p> <code>None</code> <code>patient_id</code> <code>Optional[int]</code> <p>Optional[int]. the patient ID.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict</code> <p>Dict. the feature importance.</p>"},{"location":"analysis/data_analyzer/#xiaoya.analysis.data_analyzer.DataAnalyzer.risk_curve","title":"<code>risk_curve(df, x, mask, patient_index=None, patient_id=None)</code>","text":"<p>Return data to draw risk curve of a patient.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>pd.DataFrame. the dataframe of the patient.</p> required <code>x</code> <code>List</code> <p>List. the input of the patient.</p> required <code>mask</code> <code>Optional[List]</code> <p>Optional[List]. the missing mask of the patient.</p> required <code>patient_index</code> <code>Optional[int]</code> <p>Optional[int]. the index of the patient in dataframe.</p> <code>None</code> <code>patient_id</code> <code>Optional[int]</code> <p>Optional[int]. the patient ID.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict</code> <p>Dict. the data to draw risk curve.</p>"},{"location":"analysis/data_analyzer/#xiaoya.analysis.data_analyzer.DataAnalyzer.similar_patients","title":"<code>similar_patients(x_df, x, p_df, patients, patient_index=None, patient_id=None, n_clu=10, topk=6)</code>","text":"<p>Return similar patients information.</p>"},{"location":"data/data_handler/","title":"Data Handler","text":"<p>Import user uploaded data, merge data tables, stats...</p> <p>Parameters:</p> Name Type Description Default <code>labtest_data</code> <code>DataFrame</code> <p>DataFrame.</p> required <code>events_data</code> <code>DataFrame</code> <p>DataFrame.</p> required <code>target_data</code> <code>DataFrame</code> <p>DataFrame.</p> required <code>data_path</code> <code>Path</code> <p>Path. path to save processed data, default is Path('./datasets').</p> <code>Path('./datasets')</code>"},{"location":"data/data_handler/#xiaoya.data.data_handler.DataHandler.analyze_dataset","title":"<code>analyze_dataset()</code>","text":"<p>Analyze the dataset.</p> <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>The main data in 'detail' is a List of imformation of all features.</p>"},{"location":"data/data_handler/#xiaoya.data.data_handler.DataHandler.execute","title":"<code>execute(train_size=70, val_size=10, test_size=20, seed=42)</code>","text":"<p>Execute the preprocessing pipeline, including format and merge dataframes, split the dataset, normalize the dataset, and forward fill the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>train_size</code> <code>int</code> <p>int. train set percentage.</p> <code>70</code> <code>val_size</code> <code>int</code> <p>int. val set percentage.</p> <code>10</code> <code>test_size</code> <code>int</code> <p>int. test set percentage.</p> <code>20</code> <code>seed</code> <code>int</code> <p>int. random seed.</p> <code>42</code>"},{"location":"data/data_handler/#xiaoya.data.data_handler.DataHandler.extract_features","title":"<code>extract_features(format)</code>","text":"<p>Extract features from the merged dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>str. 'labtest' or 'events' or 'target'.</p> required <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>Extracted features from raw dataframe.</p>"},{"location":"data/data_handler/#xiaoya.data.data_handler.DataHandler.format_and_merge_dataframes","title":"<code>format_and_merge_dataframes()</code>","text":"<p>Format and merge the dataframes.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The merged Dataframe.</p>"},{"location":"data/data_handler/#xiaoya.data.data_handler.DataHandler.format_dataframe","title":"<code>format_dataframe(format)</code>","text":"<p>Formats the data in the DataFrame according to the specified format.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>str.  The format to use for formatting the data, must be one of ['labtest', 'events', 'target'].</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The formatted DataFrame.</p>"},{"location":"data/data_handler/#xiaoya.data.data_handler.DataHandler.forward_fill_dataset","title":"<code>forward_fill_dataset(demographic_features, labtest_features)</code>","text":"<p>Forward fill the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>demographic_features</code> <code>List[str]</code> <p>List[str]. demographic features.</p> required <code>labtest_features</code> <code>List[str]</code> <p>List[str]. lab test features.</p> required"},{"location":"data/data_handler/#xiaoya.data.data_handler.DataHandler.list_all_features","title":"<code>list_all_features()</code>","text":"<p>List all features.</p> <p>Returns:</p> Name Type Description <code>Dict</code> <code>Dict</code> <p>All extracted features from raw dataframes.</p>"},{"location":"data/data_handler/#xiaoya.data.data_handler.DataHandler.merge_dataframes","title":"<code>merge_dataframes()</code>","text":"<p>Merge the dataframes.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The merged Dataframe.</p>"},{"location":"data/data_handler/#xiaoya.data.data_handler.DataHandler.normalize_dataset","title":"<code>normalize_dataset(normalize_features)</code>","text":"<p>Normalize the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>normalize_features</code> <code>List[str]</code> <p>List[str]. features to be normalized.</p> required"},{"location":"data/data_handler/#xiaoya.data.data_handler.DataHandler.save_processed_data","title":"<code>save_processed_data()</code>","text":"<p>Save processed data to specified directory.</p>"},{"location":"data/data_handler/#xiaoya.data.data_handler.DataHandler.save_record_time","title":"<code>save_record_time()</code>","text":"<p>Save the record time of each patient.</p>"},{"location":"data/data_handler/#xiaoya.data.data_handler.DataHandler.split_dataset","title":"<code>split_dataset(train_size=70, val_size=10, test_size=20, seed=42)</code>","text":"<p>Split the dataset into train/val/test sets.</p> <p>Parameters:</p> Name Type Description Default <code>train_size</code> <code>int</code> <p>int. train set percentage.</p> <code>70</code> <code>val_size</code> <code>int</code> <p>int. val set percentage.</p> <code>10</code> <code>test_size</code> <code>int</code> <p>int. test set percentage.</p> <code>20</code> <code>seed</code> <code>int</code> <p>int. random seed.</p> <code>42</code>"},{"location":"pipeline/pipeline/","title":"Pipeline","text":"<p>Pipeline</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>str. the model to use, available models:     - LSTM     - GRU     - AdaCare     - RNN     - MLP     - MHAGRU</p> <code>'GRU'</code> <code>task</code> <code>str</code> <p>str.  the task, default is multitask, available tasks:     - multitask     - outcome     - los</p> <code>'multitask'</code> <code>batch_size</code> <code>int</code> <p>int. the batch size, default is 64.</p> <code>64</code> <code>learning_rate</code> <code>float</code> <p>float. the learning rate, default is 0.001.</p> <code>0.001</code> <code>hidden_dim</code> <code>int</code> <p>int. the hidden dimension, default is 32.</p> <code>32</code> <code>epochs</code> <code>int</code> <p>int. the number of epochs, default is 100.</p> <code>50</code> <code>patience</code> <code>int</code> <p>int. the patience for early stopping, default is 10.</p> <code>10</code> <code>seed</code> <code>int</code> <p>int. the random seed, default is 42.</p> <code>42</code> <code>data_path</code> <code>Path</code> <p>Path. the path of the data, default is Path('./datasets').</p> <code>Path('./datasets')</code> <code>demographic_dim</code> <code>int</code> <p>int. the dimension of the demographic features.</p> <code>2</code> <code>labtest_dim</code> <code>int</code> <p>int. the dimension of the labtest features.</p> <code>73</code>"},{"location":"pipeline/pipeline/#xiaoya.pipeline.pipeline.Pipeline.execute","title":"<code>execute(model_path=None)</code>","text":"<p>Execute the pipeline, if model_path is None, then train the model, else predict directly.</p> <p>Returns:</p> Type Description <p>Dict.</p>"},{"location":"pipeline/pipeline/#xiaoya.pipeline.pipeline.Pipeline.predict","title":"<code>predict(model_path, metric_path='./metrics')</code>","text":"<p>Use the best model to predict, and then save the metrics.</p> <p>Parameters:</p> Name Type Description Default <code>model_path</code> <code>str</code> <p>str. the path of the best model.</p> required <code>metric_path</code> <code>str</code> <p>str. the path to save the metrics, default is './metrics'.</p> <code>'./metrics'</code> <p>Returns:</p> Type Description <p>Dict.</p>"},{"location":"pipeline/pipeline/#xiaoya.pipeline.pipeline.Pipeline.train","title":"<code>train(ckpt_path='./checkpoints', ckpt_name='best')</code>","text":"<p>Train the model based on the config.</p> <p>Parameters:</p> Name Type Description Default <code>ckpt_path</code> <code>str</code> <p>str. the path to save the checkpoints, default is './checkpoints'.</p> <code>'./checkpoints'</code> <code>ckpt_name</code> <code>str</code> <p>str. the name of the checkpoint file, default is 'best'.</p> <code>'best'</code>"}]}